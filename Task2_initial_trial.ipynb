{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications import vgg16\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentation_models import Unet\n",
    "from segmentation_models.backbones import get_preprocessing\n",
    "from segmentation_models.metrics import iou_score\n",
    "from segmentation_models.losses import jaccard_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "from skimage.segmentation import slic\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.util import img_as_float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_colors(x):\n",
    "    x_norm = (x-x.min())/(x.max()-x.min())\n",
    "    return x_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (256,256)\n",
    "batch_size = 2\n",
    "\n",
    "train_path = 'train_2018/'\n",
    "valid_path = 'validation_2018/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKBONE = 'inceptionresnetv2'\n",
    "preprocess_input = get_preprocessing(BACKBONE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=5\n",
    "n=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create two instances with the same arguments\n",
    "data_gen_args_train = dict(featurewise_center=False, \n",
    "                     samplewise_center=False, \n",
    "                     featurewise_std_normalization=False, \n",
    "                     samplewise_std_normalization=False,\n",
    "                     rescale=1./255,\n",
    "                     #preprocessing_function=preprocess_input,\n",
    "                     #rotation_range=10,\n",
    "                     #width_shift_range=0.05,\n",
    "                     #height_shift_range=0.05,\n",
    "                     #zoom_range=[0.9,1.1],\n",
    "                     #shear_range=0.3,\n",
    "                     #channel_shift_range=0.005,\n",
    "                     #brightness_range=[0.98,1.1],\n",
    "                     #vertical_flip=True,\n",
    "                     #horizontal_flip=True,\n",
    "                     #validation_split=0.2\n",
    "                     )\n",
    "data_gen_args_mask_train = dict(#featurewise_center=False, \n",
    "                     samplewise_center=False, \n",
    "                     featurewise_std_normalization=False, \n",
    "                     samplewise_std_normalization=False,\n",
    "                     rescale=1./255,\n",
    "                     #rotation_range=10,\n",
    "                     #width_shift_range=0.05,\n",
    "                     #height_shift_range=0.05,\n",
    "                     #zoom_range=[0.98,1.1],\n",
    "                     #shear_range=0.3,\n",
    "                     #channel_shift_range=0.005,\n",
    "                     #brightness_range=[0.9,1.1],\n",
    "                     #vertical_flip=True,\n",
    "                     #horizontal_flip=True,\n",
    "                     #validation_split=0.2\n",
    "                     )\n",
    "train_datagen = ImageDataGenerator(**data_gen_args_train)\n",
    "mask_datagen = ImageDataGenerator(**data_gen_args_mask_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_generator_train = train_datagen.flow_from_directory(\n",
    "    'train_2018/images',  # this is the target directory\n",
    "    target_size=image_size,\n",
    "    color_mode = 'rgb',\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    #subset='training',\n",
    "    #save_to_dir='train_2018/images/augmented',\n",
    "    shuffle=False,\n",
    "    seed = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_generator_train = mask_datagen.flow_from_directory(\n",
    "    'train_2018/masks/pigment_network',  # this is the target directory\n",
    "    target_size=image_size,\n",
    "    color_mode = 'grayscale',\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    #subset='training',\n",
    "    #save_to_dir='train_2018/masks/augmented',\n",
    "    shuffle=False,\n",
    "    seed = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maskB_generator_train = mask_datagen.flow_from_directory(\n",
    "    'train_2018/masks_ben/',  # this is the target directory\n",
    "    target_size=image_size,\n",
    "    color_mode = 'grayscale',\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    #subset='training',\n",
    "    #save_to_dir='train_2018/masks/augmented',\n",
    "    shuffle=False,\n",
    "    seed = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = zip(image_generator_train, mask_generator_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of images and masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_0 = image_generator_train[10][n] # [number of the batch: 0-414][number of the image in the batch: 0-3]\n",
    "mask_0=mask_generator_train[10][n]\n",
    "maskB_0=maskB_generator_train[10][n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_generator_train[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18, 16))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "ax = fig.add_subplot(1, 3, 1)\n",
    "ax.imshow(norm_colors(im_0))\n",
    "\n",
    "ax = fig.add_subplot(1, 3, 2)\n",
    "ax.imshow(np.reshape(maskB_0, image_size), cmap=\"gray\")\n",
    "\n",
    "ax = fig.add_subplot(1, 3, 3)\n",
    "ax.imshow(np.reshape(mask_0, image_size), cmap=\"gray\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation generator (no augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create two instances with the same arguments\n",
    "data_gen_args_val = dict(featurewise_center=False, \n",
    "                     samplewise_center=False, \n",
    "                     featurewise_std_normalization=False, \n",
    "                     samplewise_std_normalization=False,\n",
    "                     rescale=1./255\n",
    "                     #preprocessing_function=preprocess_input,\n",
    "                     #validation_split=0.2\n",
    "                     )\n",
    "data_gen_args_mask_val = dict(featurewise_center=False, \n",
    "                     samplewise_center=False, \n",
    "                     featurewise_std_normalization=False, \n",
    "                     samplewise_std_normalization=False,\n",
    "                     rescale=1./255,\n",
    "                     #validation_split=0.2\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_datagen = ImageDataGenerator(**data_gen_args_val)\n",
    "mask_datagen_val = ImageDataGenerator(**data_gen_args_mask_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_generator_val = val_datagen.flow_from_directory(\n",
    "    'validation_2018/images',\n",
    "    target_size=image_size,\n",
    "    color_mode = 'rgb',\n",
    "    batch_size=1,\n",
    "    class_mode=None,\n",
    "    seed=1,\n",
    "    shuffle=False)\n",
    "    #subset='validation') # set as validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_generator_val = mask_datagen_val.flow_from_directory(\n",
    "    'validation_2018/masks/pigment_network',  # this is the target directory\n",
    "    target_size=image_size,\n",
    "    color_mode = 'grayscale',\n",
    "    batch_size=1,\n",
    "    class_mode=None,\n",
    "    seed=1,\n",
    "    shuffle=False)\n",
    "    #subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maskB_generator_val = mask_datagen.flow_from_directory(\n",
    "    'validation_2018/masks_ben/',  # this is the target directory\n",
    "    target_size=image_size,\n",
    "    color_mode = 'grayscale',\n",
    "    batch_size=1,\n",
    "    class_mode=None,\n",
    "    #subset='training',\n",
    "    #save_to_dir='train_2018/masks/augmented',\n",
    "    shuffle=False,\n",
    "    seed = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_generator = zip(image_generator_val, mask_generator_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Unet(backbone_name='inceptionresnetv2', input_shape=(None, None, 3), classes=1, activation='sigmoid', \n",
    "             encoder_weights='imagenet', encoder_freeze=False, encoder_features='default', decoder_block_type='upsampling',\n",
    "             decoder_filters=(256, 128, 64, 32, 16), decoder_use_batchnorm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import binary_crossentropy\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = K.sum(intersection) / (K.sum(y_true_f*y_true_f) + K.sum(y_pred_f*y_pred_f) -K.sum(y_true_f*y_pred_f)+ smooth)\n",
    "    return 1. - score\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return (binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred))/2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_score = segmentation_models.metrics.iou_score(gt, pr, class_weights=1.0, smooth=1.0, per_image=True, threshold=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(metrics =[iou_score], loss = bce_dice_loss, optimizer=adam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0: indicating areas where the dermoscopic attribute is absent\n",
    "255: indicating areas where the the dermoscopic attribute is present -> 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model with no augmentation on data starting from Task1 weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_name = ''.join([model_name, str(start_epoch),\".hd5\"])\n",
    "model.load_weights(load_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load partly trained model\n",
    "model.load_weights('model-Unet_Alex.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_path =\"tmp/Unet1-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=10, verbose=1),\n",
    "    ReduceLROnPlateau(factor=0.1, patience=3, min_lr=0.000001, verbose=1),\n",
    "    ModelCheckpoint(filepath=save_model_path, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = image_generator_train.samples // batch_size,\n",
    "    validation_data = val_generator, \n",
    "    validation_steps = image_generator_val.samples,\n",
    "    epochs=6,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the Weights\n",
    "model_path = \"tmp/Unet-06-0.51.hdf5\"\n",
    "model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show 22 - 25 -30 - 60 cut at 0.5 - 350 -360\n",
    "view_id = 310\n",
    "x, y , z= image_generator_val[view_id], mask_generator_val[view_id], maskB_generator_val[view_id]\n",
    "    \n",
    "result = model.predict(x)\n",
    "#result = result > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18, 16))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "ax = fig.add_subplot(1, 4, 1)\n",
    "ax.imshow(np.reshape(y[0]*255, image_size), cmap=\"gray\")\n",
    "\n",
    "ax = fig.add_subplot(1, 4, 2)\n",
    "ax.imshow(np.reshape(result[0]*255, image_size), cmap=\"gray\")\n",
    "\n",
    "ax = fig.add_subplot(1, 4, 3)\n",
    "ax.imshow(norm_colors(x[0]))\n",
    "\n",
    "ax = fig.add_subplot(1, 4, 4)\n",
    "ax.imshow(np.reshape(z[0]*255, image_size), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_save(max_epoch, model_name, train_path, image_size, start_epoch = 0, test_split = 100, batchsize = 10):\n",
    "    ## Training Ids   \n",
    "   \n",
    "    if start_epoch != 0:\n",
    "        load_name = ''.join([model_name, str(start_epoch),\".hd5\"])\n",
    "        model.load_weights(load_name)\n",
    "      \n",
    "    for i in np.arange(start_epoch,max_epoch):\n",
    "        print(\"Epoch %i/%i\" %((i+1),max_epoch))\n",
    "        save_name = ''.join([model_name,str(i+1),\".hd5\"])\n",
    "        model.fit_generator(train_gen, validation_data=test_gen,steps_per_epoch=train_steps,  epochs=1)\n",
    "        model.save_weights(save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_and_predict(max_epoch,test_gen):\n",
    "    for j in range(max_epoch):\n",
    "        model = UNet()\n",
    "        model.compile(optimizer='adam', loss=bce_dice_loss, metrics=[dice_loss])\n",
    "        model_path = os.path.join(\"UNet_2018_256_ep_\" + str(j + 1) + \".hd5\")\n",
    "        model.load_weights(model_path)\n",
    "        \n",
    "        for i in range(len(test_gen)):\n",
    "            # predict the mask for each picture\n",
    "            x, y = test_gen.__getitem__(i)\n",
    "            result = model.predict(x)\n",
    "            result = result > 0.5\n",
    "            result = result[0].astype('uint8').reshape(256,256)\n",
    "            fig,ax = plt.subplots(figsize=(8,6))\n",
    "            ax.imshow(result, cmap=\"gray\")\n",
    "            ax.text(20,20,str(j + 1),color='red',fontsize=16)\n",
    "            fig.savefig(os.path.join(\"pred_Unet/pred_\" + str(i) + \"_epoch_\" + str(j + 1).zfill(2) + \".png\"))\n",
    "            plt.close()\n",
    "            if j == 0:\n",
    "                plt.imsave(os.path.join(\"pred_Unet/mask_\" + str(i) +\".png\"),y[0].astype('uint8').reshape(256,256), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model_and_predict(2,test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_save(max_epoch, model_name, train_path, image_size, start_epoch = 0, test_split = 100, batchsize = 10):\n",
    "    ## Training Ids\n",
    "    train_ids = next(os.walk(\"train_2018/images/\"))[2]\n",
    "    train_ids = [os.path.splitext(x)[0] for x in train_ids]\n",
    "    \n",
    "    test_ids = train_ids[:val_data_size]\n",
    "    train_ids = train_ids[val_data_size:]\n",
    "    \n",
    "    model = UNet()\n",
    "    model.compile(optimizer='adam', loss=\"binary_crossentropy\", metrics=[\"binary_crossentropy\"])\n",
    "    \n",
    "    if start_epoch != 0:\n",
    "        load_name = ''.join([model_name, str(start_epoch),\".hd5\"])\n",
    "        model.load_weights(load_name)\n",
    "    \n",
    "    train_gen = DataGen(train_ids, train_path, image_size=image_size, batch_size=batch_size)\n",
    "    test_gen = DataGen(test_ids, train_path, image_size=image_size, batch_size=1)\n",
    "    \n",
    "    train_steps = len(train_ids)//batch_size\n",
    "    test_steps = len(test_ids)//batch_size\n",
    "\n",
    "    for i in np.arange(start_epoch,max_epoch):\n",
    "        print(\"Epoch %i/%i\" %((i+1),max_epoch))\n",
    "        save_name = ''.join([model_name,str(i+1),\".hd5\"])\n",
    "        model.fit_generator(train_gen, validation_data=test_gen,steps_per_epoch=train_steps,  epochs=1)\n",
    "        model.save_weights(save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_save(41,\"UNet_2018_256_ep_\",\"train_2018/\",256,start_epoch=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.title(\"Learning curve\")\n",
    "plt.plot(history.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot( np.argmin(history.history[\"val_loss\"]), np.min(history.history[\"val_loss\"]), marker=\"x\", color=\"r\", label=\"best model\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"log_loss\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
